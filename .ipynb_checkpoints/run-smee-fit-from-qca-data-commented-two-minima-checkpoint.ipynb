{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e2edfc-6602-47da-9a9c-4b948241e272",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "A dataset could be created and downloaded using the new [views feature](https://docs.qcarchive.molssi.org/user_guide/datasets/caching.html).\n",
    "\n",
    "Alternatively, download live from QCArchive (see [Retrieving results](https://docs.openforcefield.org/projects/qcsubmit/en/stable/examples/retrieving-results.html) for more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb63e4b-cdeb-4167-b311-eca77bbfd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from openff.units import unit\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25529a8e-e5e7-4b43-99e6-a9ff7bf4c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcportal import PortalClient\n",
    "\n",
    "qc_client = PortalClient(\"https://api.qcarchive.molssi.org:443\", cache_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4dcf32-9224-4072-97ad-e142f9bae2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.qcsubmit.results import (\n",
    "    BasicResultCollection,\n",
    "    OptimizationResultCollection,\n",
    "    TorsionDriveResultCollection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfd078a-6e6f-4248-8f31-0cee96bfa01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pull down the torsion drive records from a dataset.\n",
    "# torsion_drive_result_collection = TorsionDriveResultCollection.from_server(\n",
    "#     client=qc_client,\n",
    "#     # small example dataset -- downloading and interacting with a dataset\n",
    "#     # can take a while!\n",
    "#     datasets=\"OpenFF Cresset Additional Coverage TorsionDrives v4.0\",\n",
    "#     spec_name=\"default\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07871a13-cf00-4e8d-8311-a7e6f500e828",
   "metadata": {},
   "source": [
    "## Convert the data into a smee/descent-friendly format\n",
    "\n",
    "The data needs to be postprocessed into a useful format for smee. Note, a lot of the functions here will benefit from parallelism as they can be very slow, some examples are provided in [Josh's repo](https://github.com/jthorton/SPICE-SMEE/blob/main/fit-v1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80194d69-3709-4181-9856-8431bcfbbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import descent.targets.energy\n",
    "\n",
    "# bohr_to_angstrom = (1 * unit.bohr).m_as(unit.angstrom)\n",
    "# hartree_to_kcal = (1 * unit.hartree * unit.avogadro_constant).m_as(\n",
    "#     unit.kilocalories_per_mole\n",
    "# )\n",
    "# hartree_to_kcal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58e13c-7893-4725-967f-8f3470700fc7",
   "metadata": {},
   "source": [
    "Ok we now want to create an [energy.Entry](https://simonboothroyd.github.io/descent/latest/reference/targets/energy/#descent.targets.energy.Entry) to be processed into a dataset. The final output is a [Huggingface dataset](https://huggingface.co/docs/datasets/en/index).\n",
    "\n",
    "How to do this will differ for optimizations and torsiondrives slightly due to the structure of the code.\n",
    "Here we look at torsiondrives, code for optimizations should be very similar but not need the `minimum_optimizations` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0818002-308d-4d98-a41b-f5e38079bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a dict to hold data by SMILES so conformers are mostly mapped together\n",
    "# # note: a more robust solution would use Molecule.are_isomorphic or similar method,\n",
    "# # but here we lazily just compare the smiles strings\n",
    "\n",
    "# data_by_smiles = defaultdict(list)\n",
    "# records_and_molecules = list(torsion_drive_result_collection.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c5d243-c78f-46ff-a413-9bc36c5838e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# records_and_molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11444575-d360-43bb-ae49-01bb10c123b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count = 0 \n",
    "# for td_record, molecule in tqdm.tqdm(records_and_molecules):\n",
    "#     # take only the optimized grid points\n",
    "#     for opt in td_record.minimum_optimizations.values():\n",
    "#         last = opt.trajectory[-1] #qc_client.get_records(record_ids=[opt.trajectory_ids_[-1]])\n",
    "#         last_mol = last.molecule\n",
    "#         mapped_smiles = last_mol.identifiers.canonical_isomeric_explicit_hydrogen_mapped_smiles\n",
    "#         coords = last_mol.geometry * bohr_to_angstrom\n",
    "#         energy = last.properties[\"return_energy\"] * hartree_to_kcal\n",
    "#         gradient = np.array(last.properties[\"scf total gradient\"]).reshape((-1, 3))\n",
    "#         forces = ((-gradient) * hartree_to_kcal / bohr_to_angstrom)\n",
    "#         entry = {\n",
    "#             \"coords\": coords,\n",
    "#             \"energy\": energy,\n",
    "#             \"forces\": forces,\n",
    "#         }\n",
    "#         data_by_smiles[mapped_smiles].append(entry)\n",
    "\n",
    "#     count += 1\n",
    "#     if count > 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17501bd-34bd-496d-9709-539739628384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to smee's expected format\n",
    "# descent_entries = []\n",
    "# for mapped_smiles, entries in data_by_smiles.items():\n",
    "#     entry = {\n",
    "#         \"smiles\": mapped_smiles,\n",
    "#         \"coords\": torch.tensor([x[\"coords\"] for x in entries]),\n",
    "#         \"energy\": torch.tensor([x[\"energy\"] for x in entries]),\n",
    "#         \"forces\": torch.tensor([x[\"forces\"] for x in entries]),\n",
    "#     }\n",
    "#     descent_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e3e0a9-e3a3-48c6-a9e7-804c7fd55b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # this dataset can get downloaded, processed once, saved and reused\n",
    "# dataset = descent.targets.energy.create_dataset(entries=descent_entries)\n",
    "# dataset.save_to_disk(\"test-smee-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba722746-0be7-4352-ac48-63629db33412",
   "metadata": {},
   "source": [
    "## Assign parameters to molecules in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38930f6d-9697-40ca-9d91-58eb8be20923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.toolkit import Molecule, ForceField\n",
    "import tqdm\n",
    "import smee.converters\n",
    "from pydantic import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb21152-bc07-4f6d-9cf3-380afe517214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if reloading data\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.Dataset.load_from_disk(\"test-smee-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f2a430-04aa-4004-9711-8f2a759c4516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reformat dataset lists to torch tensors\n",
    "dataset.set_format('torch', columns=['energy', 'coords','forces'], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0ec034c-3610-487a-85f5-584d0ad2ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coords': tensor([-0.5399,  2.1674, -3.7936,  ...,  0.1233,  3.3214,  2.1324]),\n",
       " 'energy': tensor([-322860.4375, -322860.5000, -322860.6562, -322860.7812, -322860.8125,\n",
       "         -322860.7500, -322860.6250, -322860.5000, -322860.6250, -322860.7500,\n",
       "         -322860.8125, -322860.7812, -322860.6562, -322860.5000, -322860.4375,\n",
       "         -322860.5000, -322860.6562, -322860.7812, -322860.8125, -322860.5000,\n",
       "         -322860.4375, -322860.5000, -322860.6250, -322860.7500]),\n",
       " 'forces': tensor([ 0.0021,  0.0088, -0.0046,  ..., -0.0018,  0.0060, -0.0051]),\n",
       " 'smiles': '[H:14][C:7]([H:15])([H:16])[C:6]1=[C:8]([C:3](=[N:4][O:5]1)[O:2][C:1]([H:11])([H:12])[H:13])[C:9]([H:17])([H:18])[O:10][H:19]'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is what a single entry looks like\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd3ed1-50ee-4b4b-b96e-c6e69d326b2d",
   "metadata": {},
   "source": [
    "Below we specify a starting force field.\n",
    "Normally we would initialize parameters using the Modified Seminario method,\n",
    "[example here](https://github.com/openforcefield/sage-2.2.1/blob/main/03_generate-initial-ff/create-msm-ff.py),\n",
    "but here we just start from Sage 2.2.1.\n",
    "\n",
    "[Josh's repo](https://github.com/jthorton/SPICE-SMEE/blob/main/fit-v1/training/001-expand_torsions.py)\n",
    "has examples on expanding torsions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82703447-968e-4f2e-927b-452d2d63010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_ff = ForceField(\"two-minima-force-field.offxml\", load_plugins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7077be7-38f3-445a-b5bd-f3208e2b20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import smee\n",
    "\n",
    "@smee.potentials.potential_energy_fn(\"TwoMinima\", \"twominima\")\n",
    "def compute_twominima_energy(\n",
    "    system: smee.TensorSystem,\n",
    "    potential: smee.TensorPotential,\n",
    "    conformer: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    is_batched = conformer.ndim == 3\n",
    "\n",
    "    if not is_batched:\n",
    "        conformer = torch.unsqueeze(conformer, 0)\n",
    "\n",
    "    parameters = potential.parameters\n",
    "    attributes = potential.attributes\n",
    "\n",
    "    k1 = parameters[:, 0]\n",
    "    k2 = parameters[:, 1]\n",
    "    periodicity = parameters[:, 2]\n",
    "    phase = parameters[:, 3]\n",
    "\n",
    "    central_atom = conformer[:, 0, :]\n",
    "    bonded_atoms = conformer[:, 1:, :]\n",
    "    normal_vector = torch.cross(bonded_atoms[:, 1] - bonded_atoms[:, 0], \n",
    "                                bonded_atoms[:, 2] - bonded_atoms[:, 0])\n",
    "    normal_vector = normal_vector / torch.norm(normal_vector, dim=-1, keepdim=True)\n",
    "\n",
    "    oop_vector = central_atom - bonded_atoms[:, 0]\n",
    "    theta = torch.acos(torch.sum(oop_vector * normal_vector, dim=-1) / torch.norm(oop_vector, dim=-1))\n",
    "\n",
    "    energy_1 = k1 * (1 + torch.cos(periodicity * theta - phase))\n",
    "    energy_2 = k2 * (1 + torch.cos(2 * periodicity * theta + phase))\n",
    "    \n",
    "    energy = (energy_1 - energy_2).sum(-1)\n",
    "\n",
    "    if not is_batched:\n",
    "        energy = torch.squeeze(energy, 0)\n",
    "\n",
    "    return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70caf83b-72ea-45ae-bc7a-1737596af649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smirnoff_plugins.collections.bonded import TwoMinimaCollection\n",
    "import smee.converters\n",
    "import openff.toolkit\n",
    "import openff.units\n",
    "\n",
    "KCAL_PER_MOL = openff.units.unit.kilocalories / openff.units.unit.mole\n",
    "RADIAN = openff.units.unit.radian\n",
    "UNITLESS = openff.units.unit.dimensionless\n",
    "\n",
    "def convert_twominima_handlers(\n",
    "    handlers: list[TwoMinimaCollection],\n",
    "    topologies: list[openff.toolkit.Topology],\n",
    ") -> tuple[smee.TensorPotential, list[smee.BondedParameterMap]]:\n",
    "    \"\"\"Convert Two Minima improper torsion handlers into a tensor potential and parameter maps.\"\"\"\n",
    "    \n",
    "    potential = smee.converters.openff._openff._handlers_to_potential(\n",
    "        handlers,\n",
    "        \"TwoMinima\",\n",
    "        (\"k1\", \"k2\", \"periodicity\", \"phase\"),\n",
    "        attribute_cols = (),\n",
    "    )\n",
    "    potential.fn = \"twominima\"\n",
    "\n",
    "    parameter_key_to_idx = {param_key: i for i, param_key in enumerate(potential.parameter_keys)}\n",
    "    \n",
    "    parameter_maps = []\n",
    "    \n",
    "    for handler, topology in zip(handlers, topologies, strict=True):\n",
    "        assignment_map = {}\n",
    "        \n",
    "        for key, param_key in handler.key_map.items():\n",
    "            indices = tuple(key.atom_indices)\n",
    "            assignment_map[indices] = parameter_key_to_idx[param_key]\n",
    "\n",
    "        assignment_matrix = torch.zeros(\n",
    "            (len(assignment_map), len(potential.parameters)), dtype=torch.float64\n",
    "        )\n",
    "\n",
    "        for torsion_idx, (atom_indices, parameter_idx) in enumerate(assignment_map.items()):\n",
    "            assignment_matrix[torsion_idx, parameter_idx] = 1.0\n",
    "\n",
    "        print(assignment_map)\n",
    "        parameter_map = smee.BondedParameterMap(\n",
    "            particle_idxs=torch.tensor(list(assignment_map.keys()), dtype=torch.int64),\n",
    "            assignment_matrix=assignment_matrix.to_sparse()\n",
    "        )\n",
    "\n",
    "        parameter_maps.append(parameter_map)\n",
    "\n",
    "    return potential, parameter_maps\n",
    "\n",
    "\n",
    "@smee.converters.smirnoff_parameter_converter(\n",
    "    \"TwoMinima\",\n",
    "    {\n",
    "        \"k1\": KCAL_PER_MOL,\n",
    "        \"k2\": KCAL_PER_MOL,\n",
    "        \"periodicity\": UNITLESS,\n",
    "        \"phase\": RADIAN,\n",
    "    },\n",
    ")\n",
    "def convert_twominima(\n",
    "    handlers: list[TwoMinimaCollection],\n",
    "    topologies: list[openff.toolkit.Topology],\n",
    ") -> tuple[smee.TensorPotential, list[smee.BondedParameterMap]]:\n",
    "    return convert_twominima_handlers(handlers, topologies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64b6da27-4458-4c38-a3f1-c8a6d85b65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smee.potentials.potential_energy_fn(\"TwoMinima\", \"twominima\")(compute_twominima_energy);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0932e704-4ce2-4ac5-8db2-cafa3466771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evienc/miniconda3/envs/smee-descent/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: FieldInfo(annotation=NoneType, required=False, default='VirtualSites') is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Interchange with 7 collections, non-periodic topology with 28 atoms."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openff.toolkit import ForceField\n",
    "import openff.interchange as interchange\n",
    "\n",
    "twominima_force_field = ForceField(\"two-minima-force-field.offxml\", load_plugins = True)\n",
    "\n",
    "twominima_handler = twominima_force_field.get_parameter_handler(\"TwoMinima\")\n",
    "\n",
    "# twominima_handler.add_parameter(\n",
    "#     {\n",
    "#         \"smirks\": \"[*:1]-[#7X3:2](-[*:3])-[*:4]\",\n",
    "#         \"k1\": 0.2 * KCAL_PER_MOL,\n",
    "#         \"k2\": 0.1 * KCAL_PER_MOL,\n",
    "#         \"periodicity\": 1.0 * UNITLESS,\n",
    "#         \"phase\": 0.5 * RADIAN,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "molecule = openff.toolkit.Molecule.from_smiles(\"c1n(CCO)c(C(F)(F)(F))cc1CNCCl\")\n",
    "molecule.generate_conformers(n_conformers=1)\n",
    "\n",
    "conformer = torch.tensor(molecule.conformers[0].m_as(openff.units.unit.angstrom))\n",
    "\n",
    "twominima_interchange = interchange.Interchange.from_smirnoff(\n",
    "    twominima_force_field, molecule.to_topology()\n",
    ")\n",
    "\n",
    "twominima_interchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09cea9-d206-4c84-a5ad-2427c4b3ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.toolkit import ForceField, Molecule, Topology\n",
    "\n",
    "topology = Topology.from_molecules([molecule])\n",
    "\n",
    "# Run the molecule labeling\n",
    "molecule_force_list = twominima_force_field.label_molecules(topology)\n",
    "\n",
    "# Print out a formatted description of the parameters applied to this molecule\n",
    "for mol_idx, mol_forces in enumerate(molecule_force_list):\n",
    "    print(f\"Forces for molecule {mol_idx}\")\n",
    "    for force_tag, force_dict in mol_forces.items():\n",
    "        print(f\"\\n{force_tag}:\")\n",
    "        for atom_indices, parameter in force_dict.items():\n",
    "            atomstr = \"\"\n",
    "            for idx in atom_indices:\n",
    "                atomstr += f\"{idx:>3}\"\n",
    "            print(\n",
    "                f\"atoms: {atomstr}  parameter_id: {parameter.id}  smirks {parameter.smirks}\"\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea91f930-a132-41e4-bd73-e4f2e184ea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1, 2, 5): 0, (0, 1, 5, 2): 0, (0, 2, 1, 5): 0, (0, 5, 1, 2): 0, (2, 0, 1, 5): 0, (2, 1, 0, 5): 0, (12, 13, 14, 25): 0, (12, 13, 25, 14): 0, (12, 14, 13, 25): 0, (12, 25, 13, 14): 0, (14, 12, 13, 25): 0, (14, 13, 12, 25): 0}\n"
     ]
    }
   ],
   "source": [
    "twominima_tensor_ff, [twominima_topology] = smee.converters.convert_interchange(twominima_interchange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aacf82f2-f9e1-4ad9-a0a6-78e80010c071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{(1, 2, 3, 10): 0, (1, 2, 10, 3): 0, (1, 3, 2, 10): 0, (1, 10, 2, 3): 0, (3, 1, 2, 10): 0, (3, 2, 1, 10): 0}\n",
      "{(1, 2, 3, 10): 0, (1, 2, 10, 3): 0, (1, 3, 2, 10): 0, (1, 10, 2, 3): 0, (3, 1, 2, 10): 0, (3, 2, 1, 10): 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_smiles = []\n",
    "interchanges = []\n",
    "for entry in tqdm.tqdm(dataset):\n",
    "    mol = Molecule.from_mapped_smiles(\n",
    "        entry[\"smiles\"],\n",
    "        allow_undefined_stereo=True\n",
    "    )\n",
    "    all_smiles.append(entry[\"smiles\"])\n",
    "    interchange = twominima_force_field.create_interchange(mol.to_topology())\n",
    "    interchanges.append(interchange)\n",
    "    \n",
    "smee_force_field, smee_topologies = smee.converters.convert_interchange(interchanges)\n",
    "topologies = dict(zip(all_smiles, smee_topologies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578c861-8e86-457a-baa5-08c7c669018b",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "Now we can set up and run the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e39640f-787a-43f4-a356-351bc7799d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import descent.train\n",
    "import descent.targets.energy\n",
    "\n",
    "import math\n",
    "import pathlib\n",
    "import tensorboardX\n",
    "import more_itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28802383-a0c8-4370-9f95-d57f4de291f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify which parameters to train\n",
    "# and some details about them\n",
    "# they're scaled so they're roughly on the same order of magnitude\n",
    "\n",
    "parameters = {\n",
    "    \"Bonds\": descent.train.ParameterConfig(\n",
    "        cols=[\"k\", \"length\"],\n",
    "        scales={\"k\": 1e-2, \"length\": 1.0}, # normalize so roughly equal\n",
    "        limits={\"k\":[0.0, None], \"length\": [0.0, None]}\n",
    "        # the include/exclude types are Interchange PotentialKey.id's -- typically SMIRKS\n",
    "        # include=[], <-- bonds to train. Not specifying trains all\n",
    "        # exclude=[], <-- bonds NOT to train\n",
    "    ),\n",
    "    \"Angles\": descent.train.ParameterConfig(\n",
    "        cols=[\"k\", \"angle\"],\n",
    "        scales={\"k\": 1e-2, \"angle\": 1.0},\n",
    "        limits={\"k\": [0.0, None], \"angle\": [0.0, math.pi]}\n",
    "    ),\n",
    "    \"ProperTorsions\": descent.train.ParameterConfig(\n",
    "        # fit ks\n",
    "        cols=[\"k\"],\n",
    "        scales={\"k\": 1.0},\n",
    "    ),\n",
    "    \"TwoMinima\": descent.train.ParameterConfig(\n",
    "        cols=[\"k1\", \"k2\", \"periodicity\", \"phase\"],\n",
    "        scales={\"k1\": 1.0, \"k2\": 1.0},\n",
    "        limits={\n",
    "            \"k1\": [0.0, None],\n",
    "            \"k2\": [0.0, None],\n",
    "            \"periodicity\": [1.0, 4.0],\n",
    "        }\n",
    "    )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38024384-4aff-46f9-9555-37cf60a19cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainable = descent.train.Trainable(\n",
    "    force_field=smee_force_field,\n",
    "    parameters=parameters,\n",
    "    attributes={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2f3f33d-41dd-4c92-b13b-aade5798b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional below if you want cool tensorboard logging\n",
    "def write_metrics(\n",
    "        epoch: int,\n",
    "        loss: torch.Tensor,\n",
    "        loss_energy: torch.Tensor,\n",
    "        loss_forces: torch.Tensor,\n",
    "        writer: tensorboardX.SummaryWriter\n",
    "):\n",
    "    print(f\"epoch={epoch} loss={loss.detach().item():.6f}\", flush=True)\n",
    "\n",
    "    writer.add_scalar(\"loss\", loss.detach().item(), epoch)\n",
    "    writer.add_scalar(\"loss_energy\", loss_energy.detach().item(), epoch)\n",
    "    writer.add_scalar(\"loss_forces\", loss_forces.detach().item(), epoch)\n",
    "\n",
    "    writer.add_scalar(\"rmse_energy\", math.sqrt(loss_energy.detach().item()), epoch)\n",
    "    writer.add_scalar(\"rmse_forces\", math.sqrt(loss_forces.detach().item()), epoch)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed660188-8fa5-4981-9480-ab275ad7f3ea",
   "metadata": {},
   "source": [
    "Specify some hyperparameters, n_epochs is intentionally very low to guarantee fast execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b8ba820-b2b4-496c-9dfd-3dea69f30a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4626106-ce81-4b29-90c2-21b7720c9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory to save files in\n",
    "directory = pathlib.Path(\"my-smee-fit\")\n",
    "directory.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766fcdb-5ea1-4cde-92ff-45972bea9142",
   "metadata": {},
   "source": [
    "Run fit below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "535d7e41-913d-4f32-8279-7328d2fba0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# load tensorboard extension so we can view in notebook\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdaa2af1-a22e-46f3-beed-0a208eb9b4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 loss=301.460571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 loss=309.496124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2 loss=277.562866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3 loss=268.808716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4 loss=264.627991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5 loss=249.902100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6 loss=234.439957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7 loss=225.302704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8 loss=219.073792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:00<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9 loss=209.969330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainable_parameters = trainable.to_values()\n",
    "device = trainable_parameters.device.type\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "with tensorboardX.SummaryWriter(str(directory)) as writer:\n",
    "    optimizer = torch.optim.Adam([trainable_parameters], lr=LEARNING_RATE, amsgrad=True)\n",
    "    dataset_indices = list(range(len(dataset)))\n",
    "\n",
    "    for i in range(N_EPOCHS):\n",
    "        ff = trainable.to_force_field(trainable_parameters)\n",
    "        total_loss = torch.zeros(size=(1,), device=device)\n",
    "        energy_loss = torch.zeros(size=(1,), device=device)\n",
    "        force_loss = torch.zeros(size=(1,), device=device)\n",
    "        grad = None\n",
    "    \n",
    "        for batch_ids in tqdm.tqdm(\n",
    "            more_itertools.batched(dataset_indices, BATCH_SIZE),\n",
    "            desc='Calculating energies',\n",
    "            ncols=80, total=math.ceil(len(dataset) / BATCH_SIZE)\n",
    "        ):\n",
    "            batch = dataset.select(indices=batch_ids)\n",
    "            true_batch_size = len(dataset)\n",
    "            batch_configs = sum([len(d[\"energy\"]) for d in batch])\n",
    "\n",
    "            e_ref, e_pred, f_ref, f_pred = descent.targets.energy.predict(\n",
    "                batch, ff, topologies, \"mean\"\n",
    "            )   \n",
    "            # L2 loss\n",
    "            batch_loss_energy = ((e_pred - e_ref) ** 2).sum() / true_batch_size\n",
    "            batch_loss_force = ((f_pred - f_ref) ** 2).sum() / true_batch_size\n",
    "\n",
    "            # Equal sum of L2 loss on energies and forces\n",
    "            batch_loss = batch_loss_energy + batch_loss_force\n",
    "\n",
    "            (batch_grad, ) = torch.autograd.grad(batch_loss, trainable_parameters, create_graph=True)\n",
    "            batch_grad = batch_grad.detach()\n",
    "            if grad is None:\n",
    "                grad = batch_grad\n",
    "            else:\n",
    "                grad += batch_grad\n",
    "            \n",
    "            # keep sum of squares to report MSE at the end\n",
    "            total_loss += batch_loss.detach()\n",
    "            energy_loss += batch_loss_energy.detach()\n",
    "            force_loss += batch_loss_force.detach()\n",
    "        \n",
    "        trainable_parameters.grad = grad\n",
    "        \n",
    "        write_metrics(\n",
    "            epoch=i, loss=total_loss, loss_energy=energy_loss,\n",
    "            loss_forces=force_loss, writer=writer\n",
    "        )\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            torch.save(\n",
    "                trainable.to_force_field(trainable_parameters),\n",
    "                directory / f\"force-field-epoch-{i}.pt\"\n",
    "            )\n",
    "\n",
    "    torch.save(\n",
    "        trainable.to_force_field(trainable_parameters),\n",
    "        directory / \"final-force-field.pt\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d141511-d2a4-4e28-84b1-ccd13339147c",
   "metadata": {},
   "source": [
    "Metrics can be viewed in tensorboard below.\n",
    "\n",
    "`tensorboard --logdir my-smee-fit` can also be run on command line instead of in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ba7e487-a3df-4698-8f76-ff01092a5385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5143), started 0:05:43 ago. (Use '!kill 5143' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d6be32462c38677e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d6be32462c38677e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir my-smee-fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32549d-3952-48a3-ad6f-9979659e2e97",
   "metadata": {},
   "source": [
    "## Convert back to OFFXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73fd1e41-6844-4488-bbd3-b1bd5c648aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for potential in smee_force_field.potentials:\n",
    "    handler_name = potential.parameter_keys[0].associated_handler\n",
    "\n",
    "    parameter_attrs = potential.parameter_cols\n",
    "    parameter_units = potential.parameter_units\n",
    "\n",
    "    if handler_name in [\"Bonds\", \"Angles\"]:\n",
    "        handler = starting_ff.get_parameter_handler(handler_name)\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "            for j, (p, unit) in enumerate(zip(parameter_attrs, parameter_units)):\n",
    "                setattr(ff_parameter, p, opt_parameters[j] * unit)\n",
    "\n",
    "    elif handler_name in [\"ProperTorsions\"]:\n",
    "        handler = starting_ff.get_parameter_handler(handler_name)\n",
    "        k_index = parameter_attrs.index('k')\n",
    "        p_index = parameter_attrs.index('periodicity')\n",
    "        # we need to collect the k values into a list across the entries\n",
    "        collection_data = defaultdict(dict)\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "            # find k and the periodicity\n",
    "            k = opt_parameters[k_index] * parameter_units[k_index]\n",
    "            p = int(opt_parameters[p_index])\n",
    "            collection_data[smirks][p] = k\n",
    "        # now update the force field\n",
    "        for smirks, k_s in collection_data.items():\n",
    "            ff_parameter = handler[smirks]\n",
    "            k_mapped_to_p = [k_s[p] for p in ff_parameter.periodicity]\n",
    "            ff_parameter.k = k_mapped_to_p\n",
    "\n",
    "    elif handler_name in [\"ImproperTorsions\"]:\n",
    "        k_index = parameter_attrs.index('k')\n",
    "        handler = starting_ff.get_parameter_handler(handler_name)\n",
    "        # we only fit the v2 terms for improper torsions so convert to list and set\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "            ff_parameter.k = [opt_parameters[k_index] * parameter_units[k_index]]\n",
    "\n",
    "    elif handler_name == \"TwoMinima\":\n",
    "        handler = starting_ff.get_parameter_handler(handler_name)\n",
    "        param_indices = {\n",
    "            name: i for i, name in enumerate(parameter_attrs)\n",
    "        }\n",
    "\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "\n",
    "            for param_name, unit in zip(parameter_attrs, parameter_units):\n",
    "                value = opt_parameters[param_indices[param_name]] * unit\n",
    "                setattr(ff_parameter, param_name, value)\n",
    "\n",
    "\n",
    "starting_ff.to_file(\"two_minima_final-force-field.offxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fb56d-0894-4a4e-bac4-26c9f5c12ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
