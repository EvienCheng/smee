{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e2edfc-6602-47da-9a9c-4b948241e272",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "A dataset could be created and downloaded using the new [views feature](https://docs.qcarchive.molssi.org/user_guide/datasets/caching.html).\n",
    "\n",
    "Alternatively, download live from QCArchive (see [Retrieving results](https://docs.openforcefield.org/projects/qcsubmit/en/stable/examples/retrieving-results.html) for more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb63e4b-cdeb-4167-b311-eca77bbfd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from openff.units import unit\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25529a8e-e5e7-4b43-99e6-a9ff7bf4c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcportal import PortalClient\n",
    "\n",
    "qc_client = PortalClient(\"https://api.qcarchive.molssi.org:443\", cache_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4dcf32-9224-4072-97ad-e142f9bae2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.qcsubmit.results import (\n",
    "    BasicResultCollection,\n",
    "    OptimizationResultCollection,\n",
    "    TorsionDriveResultCollection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfd078a-6e6f-4248-8f31-0cee96bfa01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pull down the torsion drive records from a dataset.\n",
    "# torsion_drive_result_collection = TorsionDriveResultCollection.from_server(\n",
    "#     client=qc_client,\n",
    "#     # small example dataset -- downloading and interacting with a dataset\n",
    "#     # can take a while!\n",
    "#     datasets=\"OpenFF Cresset Additional Coverage TorsionDrives v4.0\",\n",
    "#     spec_name=\"default\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07871a13-cf00-4e8d-8311-a7e6f500e828",
   "metadata": {},
   "source": [
    "## Convert the data into a smee/descent-friendly format\n",
    "\n",
    "The data needs to be postprocessed into a useful format for smee. Note, a lot of the functions here will benefit from parallelism as they can be very slow, some examples are provided in [Josh's repo](https://github.com/jthorton/SPICE-SMEE/blob/main/fit-v1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80194d69-3709-4181-9856-8431bcfbbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import descent.targets.energy\n",
    "\n",
    "# bohr_to_angstrom = (1 * unit.bohr).m_as(unit.angstrom)\n",
    "# hartree_to_kcal = (1 * unit.hartree * unit.avogadro_constant).m_as(\n",
    "#     unit.kilocalories_per_mole\n",
    "# )\n",
    "# hartree_to_kcal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58e13c-7893-4725-967f-8f3470700fc7",
   "metadata": {},
   "source": [
    "Ok we now want to create an [energy.Entry](https://simonboothroyd.github.io/descent/latest/reference/targets/energy/#descent.targets.energy.Entry) to be processed into a dataset. The final output is a [Huggingface dataset](https://huggingface.co/docs/datasets/en/index).\n",
    "\n",
    "How to do this will differ for optimizations and torsiondrives slightly due to the structure of the code.\n",
    "Here we look at torsiondrives, code for optimizations should be very similar but not need the `minimum_optimizations` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0818002-308d-4d98-a41b-f5e38079bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a dict to hold data by SMILES so conformers are mostly mapped together\n",
    "# # note: a more robust solution would use Molecule.are_isomorphic or similar method,\n",
    "# # but here we lazily just compare the smiles strings\n",
    "\n",
    "# data_by_smiles = defaultdict(list)\n",
    "# records_and_molecules = list(torsion_drive_result_collection.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c5d243-c78f-46ff-a413-9bc36c5838e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# records_and_molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11444575-d360-43bb-ae49-01bb10c123b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count = 0 \n",
    "# for td_record, molecule in tqdm.tqdm(records_and_molecules):\n",
    "#     # take only the optimized grid points\n",
    "#     for opt in td_record.minimum_optimizations.values():\n",
    "#         last = opt.trajectory[-1] #qc_client.get_records(record_ids=[opt.trajectory_ids_[-1]])\n",
    "#         last_mol = last.molecule\n",
    "#         mapped_smiles = last_mol.identifiers.canonical_isomeric_explicit_hydrogen_mapped_smiles\n",
    "#         coords = last_mol.geometry * bohr_to_angstrom\n",
    "#         energy = last.properties[\"return_energy\"] * hartree_to_kcal\n",
    "#         gradient = np.array(last.properties[\"scf total gradient\"]).reshape((-1, 3))\n",
    "#         forces = ((-gradient) * hartree_to_kcal / bohr_to_angstrom)\n",
    "#         entry = {\n",
    "#             \"coords\": coords,\n",
    "#             \"energy\": energy,\n",
    "#             \"forces\": forces,\n",
    "#         }\n",
    "#         data_by_smiles[mapped_smiles].append(entry)\n",
    "\n",
    "#     count += 1\n",
    "#     if count > 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17501bd-34bd-496d-9709-539739628384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to smee's expected format\n",
    "# descent_entries = []\n",
    "# for mapped_smiles, entries in data_by_smiles.items():\n",
    "#     entry = {\n",
    "#         \"smiles\": mapped_smiles,\n",
    "#         \"coords\": torch.tensor([x[\"coords\"] for x in entries]),\n",
    "#         \"energy\": torch.tensor([x[\"energy\"] for x in entries]),\n",
    "#         \"forces\": torch.tensor([x[\"forces\"] for x in entries]),\n",
    "#     }\n",
    "#     descent_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e3e0a9-e3a3-48c6-a9e7-804c7fd55b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # this dataset can get downloaded, processed once, saved and reused\n",
    "# dataset = descent.targets.energy.create_dataset(entries=descent_entries)\n",
    "# dataset.save_to_disk(\"test-smee-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba722746-0be7-4352-ac48-63629db33412",
   "metadata": {},
   "source": [
    "## Assign parameters to molecules in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38930f6d-9697-40ca-9d91-58eb8be20923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.toolkit import Molecule, ForceField\n",
    "import tqdm\n",
    "import smee.converters\n",
    "from pydantic import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb21152-bc07-4f6d-9cf3-380afe517214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if reloading data\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.Dataset.load_from_disk(\"test-smee-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f2a430-04aa-4004-9711-8f2a759c4516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reformat dataset lists to torch tensors\n",
    "dataset.set_format('torch', columns=['energy', 'coords','forces'], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0ec034c-3610-487a-85f5-584d0ad2ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coords': tensor([-2.7269, -1.4295, -0.0181,  ..., -0.1040,  0.5878, -1.0884]),\n",
       " 'energy': tensor([-264210.7812, -264210.3438, -264209.5312, -264208.5312, -264207.7188,\n",
       "         -264208.7812, -264210.3438, -264211.3125, -264212.4062, -264214.4375,\n",
       "         -264217.4375, -264220.2812, -264222.5000, -264211.6250, -264212.4688,\n",
       "         -264212.9688, -264213.6250, -264215.5000, -264218.2500, -264223.8438,\n",
       "         -264224.3750, -264224.1562, -264223.0625, -264221.0625]),\n",
       " 'forces': tensor([ 0.4746, -0.5829, -1.1677,  ..., -0.0039,  0.0169,  0.0220]),\n",
       " 'smiles': '[H:6][C@:5]1([C:7]([C:8]([C:9]([N+:10]1([H:21])[H:22])([H:19])[H:20])([H:17])[H:18])([H:15])[H:16])[C:2](=[O:1])[N:3]([H:11])[C:4]([H:12])([H:13])[H:14]'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is what a single entry looks like\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd3ed1-50ee-4b4b-b96e-c6e69d326b2d",
   "metadata": {},
   "source": [
    "Below we specify a starting force field.\n",
    "Normally we would initialize parameters using the Modified Seminario method,\n",
    "[example here](https://github.com/openforcefield/sage-2.2.1/blob/main/03_generate-initial-ff/create-msm-ff.py),\n",
    "but here we just start from Sage 2.2.1.\n",
    "\n",
    "[Josh's repo](https://github.com/jthorton/SPICE-SMEE/blob/main/fit-v1/training/001-expand_torsions.py)\n",
    "has examples on expanding torsions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82703447-968e-4f2e-927b-452d2d63010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting_ff = ForceField(\"lee-krimm-force-field.offxml\", load_plugins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7077be7-38f3-445a-b5bd-f3208e2b20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import smee\n",
    "\n",
    "# @smee.potentials.potential_energy_fn(\"LeeKrimm\", \"leekrimm\")\n",
    "# def compute_leekrimm_energy(\n",
    "#     system: smee.TensorSystem,\n",
    "#     potential: smee.TensorPotential,\n",
    "#     conformer: torch.Tensor,\n",
    "# ) -> torch.Tensor:\n",
    "#     if conformer.ndim == 2:\n",
    "#         conformer = conformer.unsqueeze(0)\n",
    "\n",
    "#     particle_idxs = smee.potentials.broadcast_idxs(system, potential)\n",
    "#     n_matches = particle_idxs.shape[0]\n",
    "\n",
    "#     if n_matches == 0:\n",
    "#         return torch.zeros(\n",
    "#             (conformer.shape[0],),\n",
    "#             dtype=conformer.dtype,\n",
    "#             device=conformer.device\n",
    "#         )\n",
    "\n",
    "#     parameters = smee.potentials.broadcast_parameters(system, potential)\n",
    "\n",
    "#     v2 = parameters[:, potential.parameter_cols.index(\"V2\")]\n",
    "#     v4 = parameters[:, potential.parameter_cols.index(\"V4\")]\n",
    "#     t  = parameters[:, potential.parameter_cols.index(\"t\")]\n",
    "#     s  = parameters[:, potential.parameter_cols.index(\"s\")]\n",
    "\n",
    "#     conf_idx = torch.arange(conformer.shape[0], device=conformer.device)[:, None]\n",
    "\n",
    "#     a = conformer[conf_idx, particle_idxs[:, 0]]\n",
    "#     b = conformer[conf_idx, particle_idxs[:, 1]]\n",
    "#     c = conformer[conf_idx, particle_idxs[:, 2]]\n",
    "#     d = conformer[conf_idx, particle_idxs[:, 3]]\n",
    "\n",
    "#     bc = b - c\n",
    "#     dc = d - c\n",
    "#     normal_vector = torch.cross(bc, dc, dim=-1)\n",
    "#     oop_vector = a - b\n",
    "\n",
    "#     cos_theta = torch.sum(oop_vector * normal_vector, dim=-1) / (\n",
    "#         torch.norm(oop_vector, dim=-1) * torch.norm(normal_vector, dim=-1)\n",
    "#     )\n",
    "#     cos_theta = torch.clamp(cos_theta, -1.0, 1.0)\n",
    "#     h = torch.acos(cos_theta)\n",
    "\n",
    "#     h_abs = torch.abs(h)\n",
    "#     denom = 1.0 - torch.pow(h_abs, s)\n",
    "#     safe_denom = torch.where(denom == 0, torch.tensor(1e-8, device=denom.device), denom)\n",
    "\n",
    "#     frac = torch.pow(h_abs, t) / safe_denom\n",
    "#     energy = (v2 * frac**2) + (v4 * frac**4)\n",
    "\n",
    "#     energy = energy.sum(dim=-1)\n",
    "\n",
    "#     return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70caf83b-72ea-45ae-bc7a-1737596af649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smirnoff_plugins.collections.valence import SMIRNOFFLeeKrimmCollection\n",
    "from smee import TensorPotential, ValenceParameterMap\n",
    "import smee.converters\n",
    "import torch\n",
    "import openff.toolkit\n",
    "import openff.units\n",
    "\n",
    "# def convert_leekrimm_handlers(\n",
    "#     handlers: list[SMIRNOFFLeeKrimmCollection],\n",
    "#     topologies: list[openff.toolkit.Topology],\n",
    "# ) -> tuple[TensorPotential, list[ValenceParameterMap]]:\n",
    "    \n",
    "#     potential = smee.converters.openff._openff._handlers_to_potential(\n",
    "#         handlers,\n",
    "#         \"LeeKrimm\",\n",
    "#         (\"V2\", \"V4\", \"t\", \"s\"),\n",
    "#         attribute_cols=(),\n",
    "#     )\n",
    "#     potential.fn = \"leekrimm\"\n",
    "\n",
    "#     parameter_key_to_idx = {param_key: i for i, param_key in enumerate(potential.parameter_keys)}\n",
    "#     parameter_maps = []\n",
    "\n",
    "#     for handler, topology in zip(handlers, topologies, strict=True):\n",
    "#         assignment_map = {}\n",
    "\n",
    "#         for key, param_key in handler.key_map.items():\n",
    "#             indices = tuple(key.atom_indices)\n",
    "#             assignment_map[indices] = parameter_key_to_idx[param_key]\n",
    "\n",
    "#         assignment_matrix = torch.zeros(\n",
    "#             (len(assignment_map), len(potential.parameters)), dtype=torch.float64\n",
    "#         )\n",
    "#         for torsion_idx, (atom_indices, parameter_idx) in enumerate(assignment_map.items()):\n",
    "#             assignment_matrix[torsion_idx, parameter_idx] = 1.0\n",
    "\n",
    "#         parameter_map = BondedParameterMap(\n",
    "#             particle_idxs=torch.tensor(list(assignment_map.keys()), dtype=torch.int64),\n",
    "#             assignment_matrix=assignment_matrix.to_sparse()\n",
    "#         )\n",
    "\n",
    "#         parameter_maps.append(parameter_map)\n",
    "\n",
    "#     return potential, parameter_maps\n",
    "\n",
    "# KCAL_PER_MOL = openff.units.unit.kilocalories / openff.units.unit.mole\n",
    "# RADIAN = openff.units.unit.radian\n",
    "# UNITLESS = openff.units.unit.dimensionless\n",
    "\n",
    "# @smee.converters.smirnoff_parameter_converter(\n",
    "#     \"LeeKrimm\",\n",
    "#     {\n",
    "#         \"V2\": KCAL_PER_MOL,\n",
    "#         \"V4\": KCAL_PER_MOL,\n",
    "#         \"t\": UNITLESS,\n",
    "#         \"s\": UNITLESS,\n",
    "#     },\n",
    "# )\n",
    "# def convert_leekrimm(\n",
    "#     handlers: list[SMIRNOFFLeeKrimmCollection],\n",
    "#     topologies: list[openff.toolkit.Topology],\n",
    "# ) -> tuple[TensorPotential, list[ValenceParameterMap]]:\n",
    "#     return convert_leekrimm_handlers(handlers, topologies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64b6da27-4458-4c38-a3f1-c8a6d85b65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smee.potentials.potential_energy_fn(\"LeeKrimm\", \"leekrimm\")(compute_leekrimm_energy);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0932e704-4ce2-4ac5-8db2-cafa3466771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interchange with 7 collections, non-periodic topology with 28 atoms."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openff.toolkit import ForceField, Molecule\n",
    "import openff.interchange as interchange\n",
    "import torch\n",
    "import openff.units\n",
    "\n",
    "leekrimm_force_field = ForceField(\"lee_krimm.offxml\", load_plugins=True)\n",
    "leekrimm_force_field.deregister_parameter_handler(\"ImproperTorsions\")\n",
    "\n",
    "leekrimm_handler = leekrimm_force_field.get_parameter_handler(\"LeeKrimm\")\n",
    "\n",
    "molecule = Molecule.from_smiles(\"c1n(CCO)c(C(F)(F)(F))cc1CNCCl\")\n",
    "molecule.generate_conformers(n_conformers=1)\n",
    "\n",
    "conformer = torch.tensor(molecule.conformers[0].m_as(openff.units.unit.angstrom))\n",
    "\n",
    "leekrimm_interchange = interchange.Interchange.from_smirnoff(\n",
    "    leekrimm_force_field, molecule.to_topology()\n",
    ")\n",
    "\n",
    "leekrimm_interchange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de09cea9-d206-4c84-a5ad-2427c4b3ed2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forces for molecule 0\n",
      "\n",
      "Constraints:\n",
      "\n",
      "Bonds:\n",
      "atoms:   0  1  parameter_id: b8  smirks [#6X3:1]-[#7X3:2]\n",
      "atoms:   0 11  parameter_id: b6  smirks [#6X3:1]=[#6X3:2]\n",
      "atoms:   0 16  parameter_id: b85  smirks [#6X3:1]-[#1:2]\n",
      "atoms:   1  2  parameter_id: b7  smirks [#6:1]-[#7:2]\n",
      "atoms:   1  5  parameter_id: b8  smirks [#6X3:1]-[#7X3:2]\n",
      "atoms:   2  3  parameter_id: b1  smirks [#6X4:1]-[#6X4:2]\n",
      "atoms:   2 17  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "atoms:   2 18  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "atoms:   3  4  parameter_id: b14  smirks [#6:1]-[#8:2]\n",
      "atoms:   3 19  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "atoms:   3 20  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "atoms:   4 21  parameter_id: b88  smirks [#8:1]-[#1:2]\n",
      "atoms:   5  6  parameter_id: b2  smirks [#6X4:1]-[#6X3:2]\n",
      "atoms:   5 10  parameter_id: b6  smirks [#6X3:1]=[#6X3:2]\n",
      "atoms:   6  7  parameter_id: b69  smirks [#6X4:1]-[#9:2]\n",
      "atoms:   6  8  parameter_id: b69  smirks [#6X4:1]-[#9:2]\n",
      "atoms:   6  9  parameter_id: b69  smirks [#6X4:1]-[#9:2]\n",
      "atoms:  10 11  parameter_id: b4  smirks [#6X3:1]-[#6X3:2]\n",
      "atoms:  10 22  parameter_id: b85  smirks [#6X3:1]-[#1:2]\n",
      "atoms:  11 12  parameter_id: b2  smirks [#6X4:1]-[#6X3:2]\n",
      "atoms:  12 13  parameter_id: b7  smirks [#6:1]-[#7:2]\n",
      "atoms:  12 23  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "atoms:  12 24  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "atoms:  13 14  parameter_id: b7  smirks [#6:1]-[#7:2]\n",
      "atoms:  13 25  parameter_id: b87  smirks [#7:1]-[#1:2]\n",
      "atoms:  14 15  parameter_id: b71  smirks [#6X4:1]-[#17:2]\n",
      "atoms:  14 26  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "atoms:  14 27  parameter_id: b84  smirks [#6X4:1]-[#1:2]\n",
      "\n",
      "Angles:\n",
      "atoms:   0  1  2  parameter_id: a20  smirks [*:1]~[#7X3$(*~[#6X3,#6X2,#7X2+0]):2]~[*:3]\n",
      "atoms:   0  1  5  parameter_id: a20  smirks [*:1]~[#7X3$(*~[#6X3,#6X2,#7X2+0]):2]~[*:3]\n",
      "atoms:   0 11 10  parameter_id: a10  smirks [*:1]~[#6X3:2]~[*:3]\n",
      "atoms:   0 11 12  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:   1  0 11  parameter_id: a10  smirks [*:1]~[#6X3:2]~[*:3]\n",
      "atoms:   1  0 16  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:   1  2  3  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   1  2 17  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   1  2 18  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   1  5  6  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:   1  5 10  parameter_id: a10  smirks [*:1]~[#6X3:2]~[*:3]\n",
      "atoms:   2  1  5  parameter_id: a20  smirks [*:1]~[#7X3$(*~[#6X3,#6X2,#7X2+0]):2]~[*:3]\n",
      "atoms:   2  3  4  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   2  3 19  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   2  3 20  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   3  2 17  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   3  2 18  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   3  4 21  parameter_id: a28  smirks [*:1]-[#8:2]-[*:3]\n",
      "atoms:   4  3 19  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   4  3 20  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   5  6  7  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   5  6  8  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   5  6  9  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   5 10 11  parameter_id: a10  smirks [*:1]~[#6X3:2]~[*:3]\n",
      "atoms:   5 10 22  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:   6  5 10  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:   7  6  8  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   7  6  9  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:   8  6  9  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  10 11 12  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:  11  0 16  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:  11 10 22  parameter_id: a14  smirks [*:1]~;!@[*;X3;r5:2]~;@[*;r5:3]\n",
      "atoms:  11 12 13  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  11 12 23  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  11 12 24  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  12 13 14  parameter_id: a18  smirks [*:1]~[#7X4,#7X3,#7X2-1:2]~[*:3]\n",
      "atoms:  12 13 25  parameter_id: a19  smirks [#1:1]-[#7X4,#7X3,#7X2-1:2]-[*:3]\n",
      "atoms:  13 12 23  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  13 12 24  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  13 14 15  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  13 14 26  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  13 14 27  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  14 13 25  parameter_id: a19  smirks [#1:1]-[#7X4,#7X3,#7X2-1:2]-[*:3]\n",
      "atoms:  15 14 26  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  15 14 27  parameter_id: a1  smirks [*:1]~[#6X4:2]-[*:3]\n",
      "atoms:  17  2 18  parameter_id: a2  smirks [#1:1]-[#6X4:2]-[#1:3]\n",
      "atoms:  19  3 20  parameter_id: a2  smirks [#1:1]-[#6X4:2]-[#1:3]\n",
      "atoms:  23 12 24  parameter_id: a2  smirks [#1:1]-[#6X4:2]-[#1:3]\n",
      "atoms:  26 14 27  parameter_id: a2  smirks [#1:1]-[#6X4:2]-[#1:3]\n",
      "\n",
      "ProperTorsions:\n",
      "atoms:   0  1  2  3  parameter_id: t64  smirks [*:1]-[#6X4:2]-[#7X3$(*~[#6X3,#6X2]):3]~[*:4]\n",
      "atoms:   0  1  2 17  parameter_id: t64  smirks [*:1]-[#6X4:2]-[#7X3$(*~[#6X3,#6X2]):3]~[*:4]\n",
      "atoms:   0  1  2 18  parameter_id: t64  smirks [*:1]-[#6X4:2]-[#7X3$(*~[#6X3,#6X2]):3]~[*:4]\n",
      "atoms:   0  1  5  6  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   0  1  5 10  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   0 11 10  5  parameter_id: t43  smirks [*:1]~[#6X3:2]-[#6X3:3]~[*:4]\n",
      "atoms:   0 11 10 22  parameter_id: t43  smirks [*:1]~[#6X3:2]-[#6X3:3]~[*:4]\n",
      "atoms:   0 11 12 13  parameter_id: t18  smirks [*:1]-[#6X4:2]-[#6X3:3]=[*:4]\n",
      "atoms:   0 11 12 23  parameter_id: t20  smirks [#1:1]-[#6X4:2]-[#6X3:3]=[#6X3:4]\n",
      "atoms:   0 11 12 24  parameter_id: t20  smirks [#1:1]-[#6X4:2]-[#6X3:3]=[#6X3:4]\n",
      "atoms:   1  0 11 10  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:   1  0 11 12  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:   1  2  3  4  parameter_id: t1  smirks [*:1]-[#6X4:2]-[#6X4:3]-[*:4]\n",
      "atoms:   1  2  3 19  parameter_id: t1  smirks [*:1]-[#6X4:2]-[#6X4:3]-[*:4]\n",
      "atoms:   1  2  3 20  parameter_id: t1  smirks [*:1]-[#6X4:2]-[#6X4:3]-[*:4]\n",
      "atoms:   1  5  6  7  parameter_id: t17  smirks [*:1]~[#6X3:2]-[#6X4:3]-[*:4]\n",
      "atoms:   1  5  6  8  parameter_id: t17  smirks [*:1]~[#6X3:2]-[#6X4:3]-[*:4]\n",
      "atoms:   1  5  6  9  parameter_id: t17  smirks [*:1]~[#6X3:2]-[#6X4:3]-[*:4]\n",
      "atoms:   1  5 10 11  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:   1  5 10 22  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:   2  1  0 11  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   2  1  0 16  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   2  1  5  6  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   2  1  5 10  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   2  3  4 21  parameter_id: t94  smirks [#6X4:1]-[#6X4:2]-[#8X2H1:3]-[#1:4]\n",
      "atoms:   3  2  1  5  parameter_id: t64  smirks [*:1]-[#6X4:2]-[#7X3$(*~[#6X3,#6X2]):3]~[*:4]\n",
      "atoms:   4  3  2 17  parameter_id: t9  smirks [#1:1]-[#6X4:2]-[#6X4:3]-[#8X2:4]\n",
      "atoms:   4  3  2 18  parameter_id: t9  smirks [#1:1]-[#6X4:2]-[#6X4:3]-[#8X2:4]\n",
      "atoms:   5  1  0 11  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   5  1  0 16  parameter_id: t80  smirks [*:1]-[#7X3;r5:2]-@[#6X3;r5:3]~[*:4]\n",
      "atoms:   5  1  2 17  parameter_id: t64  smirks [*:1]-[#6X4:2]-[#7X3$(*~[#6X3,#6X2]):3]~[*:4]\n",
      "atoms:   5  1  2 18  parameter_id: t64  smirks [*:1]-[#6X4:2]-[#7X3$(*~[#6X3,#6X2]):3]~[*:4]\n",
      "atoms:   5 10 11 12  parameter_id: t43  smirks [*:1]~[#6X3:2]-[#6X3:3]~[*:4]\n",
      "atoms:   6  5 10 11  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:   6  5 10 22  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:   7  6  5 10  parameter_id: t18  smirks [*:1]-[#6X4:2]-[#6X3:3]=[*:4]\n",
      "atoms:   8  6  5 10  parameter_id: t18  smirks [*:1]-[#6X4:2]-[#6X3:3]=[*:4]\n",
      "atoms:   9  6  5 10  parameter_id: t18  smirks [*:1]-[#6X4:2]-[#6X3:3]=[*:4]\n",
      "atoms:  10 11  0 16  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:  10 11 12 13  parameter_id: t17  smirks [*:1]~[#6X3:2]-[#6X4:3]-[*:4]\n",
      "atoms:  10 11 12 23  parameter_id: t17  smirks [*:1]~[#6X3:2]-[#6X4:3]-[*:4]\n",
      "atoms:  10 11 12 24  parameter_id: t17  smirks [*:1]~[#6X3:2]-[#6X4:3]-[*:4]\n",
      "atoms:  11 12 13 14  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  11 12 13 25  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  12 11  0 16  parameter_id: t45  smirks [*:1]-,:[#6X3:2]=[#6X3:3]-,:[*:4]\n",
      "atoms:  12 11 10 22  parameter_id: t43  smirks [*:1]~[#6X3:2]-[#6X3:3]~[*:4]\n",
      "atoms:  12 13 14 15  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  12 13 14 26  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  12 13 14 27  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  14 13 12 23  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  14 13 12 24  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  15 14 13 25  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  17  2  3 19  parameter_id: t3  smirks [#1:1]-[#6X4:2]-[#6X4:3]-[#1:4]\n",
      "atoms:  17  2  3 20  parameter_id: t3  smirks [#1:1]-[#6X4:2]-[#6X4:3]-[#1:4]\n",
      "atoms:  18  2  3 19  parameter_id: t3  smirks [#1:1]-[#6X4:2]-[#6X4:3]-[#1:4]\n",
      "atoms:  18  2  3 20  parameter_id: t3  smirks [#1:1]-[#6X4:2]-[#6X4:3]-[#1:4]\n",
      "atoms:  19  3  4 21  parameter_id: t93  smirks [*:1]-[#6X4:2]-[#8X2:3]-[#1:4]\n",
      "atoms:  20  3  4 21  parameter_id: t93  smirks [*:1]-[#6X4:2]-[#8X2:3]-[#1:4]\n",
      "atoms:  23 12 13 25  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  24 12 13 25  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  25 13 14 26  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "atoms:  25 13 14 27  parameter_id: t51  smirks [*:1]~[#6X4:2]-[#7X3:3]~[*:4]\n",
      "\n",
      "vdW:\n",
      "atoms:   0  parameter_id: n14  smirks [#6:1]\n",
      "atoms:   1  parameter_id: n20  smirks [#7:1]\n",
      "atoms:   2  parameter_id: n16  smirks [#6X4:1]\n",
      "atoms:   3  parameter_id: n16  smirks [#6X4:1]\n",
      "atoms:   4  parameter_id: n19  smirks [#8X2H1+0:1]\n",
      "atoms:   5  parameter_id: n14  smirks [#6:1]\n",
      "atoms:   6  parameter_id: n16  smirks [#6X4:1]\n",
      "atoms:   7  parameter_id: n23  smirks [#9:1]\n",
      "atoms:   8  parameter_id: n23  smirks [#9:1]\n",
      "atoms:   9  parameter_id: n23  smirks [#9:1]\n",
      "atoms:  10  parameter_id: n14  smirks [#6:1]\n",
      "atoms:  11  parameter_id: n14  smirks [#6:1]\n",
      "atoms:  12  parameter_id: n16  smirks [#6X4:1]\n",
      "atoms:  13  parameter_id: n20  smirks [#7:1]\n",
      "atoms:  14  parameter_id: n16  smirks [#6X4:1]\n",
      "atoms:  15  parameter_id: n24  smirks [#17:1]\n",
      "atoms:  16  parameter_id: n8  smirks [#1:1]-[#6X3]~[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  17  parameter_id: n3  smirks [#1:1]-[#6X4]-[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  18  parameter_id: n3  smirks [#1:1]-[#6X4]-[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  19  parameter_id: n3  smirks [#1:1]-[#6X4]-[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  20  parameter_id: n3  smirks [#1:1]-[#6X4]-[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  21  parameter_id: n12  smirks [#1:1]-[#8]\n",
      "atoms:  22  parameter_id: n7  smirks [#1:1]-[#6X3]\n",
      "atoms:  23  parameter_id: n3  smirks [#1:1]-[#6X4]-[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  24  parameter_id: n3  smirks [#1:1]-[#6X4]-[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  25  parameter_id: n11  smirks [#1:1]-[#7]\n",
      "atoms:  26  parameter_id: n4  smirks [#1:1]-[#6X4](-[#7,#8,#9,#16,#17,#35])-[#7,#8,#9,#16,#17,#35]\n",
      "atoms:  27  parameter_id: n4  smirks [#1:1]-[#6X4](-[#7,#8,#9,#16,#17,#35])-[#7,#8,#9,#16,#17,#35]\n",
      "\n",
      "Electrostatics:\n",
      "\n",
      "LibraryCharges:\n",
      "\n",
      "ToolkitAM1BCC:\n",
      "\n",
      "LeeKrimm:\n",
      "atoms:   0  1  2  5  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:   0  1  5  2  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:   0  2  1  5  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:   0  5  1  2  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:   2  0  1  5  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:   2  1  0  5  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:  12 13 14 25  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:  12 13 25 14  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:  12 14 13 25  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:  12 25 13 14  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:  14 12 13 25  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n",
      "atoms:  14 13 12 25  parameter_id: lk1  smirks [*:1]~[#7X3:2](~[*:3])~[*:4]\n"
     ]
    }
   ],
   "source": [
    "from openff.toolkit import ForceField, Molecule, Topology\n",
    "\n",
    "topology = Topology.from_molecules([molecule])\n",
    "\n",
    "molecule_force_list = leekrimm_force_field.label_molecules(topology)\n",
    "\n",
    "for mol_idx, mol_forces in enumerate(molecule_force_list):\n",
    "    print(f\"Forces for molecule {mol_idx}\")\n",
    "    for force_tag, force_dict in mol_forces.items():\n",
    "        print(f\"\\n{force_tag}:\")\n",
    "        for atom_indices, parameter in force_dict.items():\n",
    "            atomstr = \"\"\n",
    "            for idx in atom_indices:\n",
    "                atomstr += f\"{idx:>3}\"\n",
    "            print(\n",
    "                f\"atoms: {atomstr}  parameter_id: {parameter.id}  smirks {parameter.smirks}\"\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea91f930-a132-41e4-bd73-e4f2e184ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "leekrimm_tensor_ff, [leekrimm_topology] = smee.converters.convert_interchange(leekrimm_interchange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aacf82f2-f9e1-4ad9-a0a6-78e80010c071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "all_smiles = []\n",
    "interchanges = []\n",
    "for entry in tqdm.tqdm(dataset):\n",
    "    mol = Molecule.from_mapped_smiles(\n",
    "        entry[\"smiles\"],\n",
    "        allow_undefined_stereo=True\n",
    "    )\n",
    "    all_smiles.append(entry[\"smiles\"])\n",
    "    interchange = leekrimm_force_field.create_interchange(mol.to_topology())\n",
    "    interchanges.append(interchange)\n",
    "    \n",
    "smee_force_field, smee_topologies = smee.converters.convert_interchange(interchanges)\n",
    "topologies = dict(zip(all_smiles, smee_topologies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578c861-8e86-457a-baa5-08c7c669018b",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "Now we can set up and run the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e39640f-787a-43f4-a356-351bc7799d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import descent.train\n",
    "import descent.targets.energy\n",
    "\n",
    "import math\n",
    "import pathlib\n",
    "import tensorboardX\n",
    "import more_itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28802383-a0c8-4370-9f95-d57f4de291f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify which parameters to train\n",
    "# and some details about them\n",
    "# they're scaled so they're roughly on the same order of magnitude\n",
    "\n",
    "parameters = {\n",
    "    \"Bonds\": descent.train.ParameterConfig(\n",
    "        cols=[\"k\", \"length\"],\n",
    "        scales={\"k\": 1e-2, \"length\": 1.0}, # normalize so roughly equal\n",
    "        limits={\"k\":[0.0, None], \"length\": [0.0, None]}\n",
    "        # the include/exclude types are Interchange PotentialKey.id's -- typically SMIRKS\n",
    "        # include=[], <-- bonds to train. Not specifying trains all\n",
    "        # exclude=[], <-- bonds NOT to train\n",
    "    ),\n",
    "    \"Angles\": descent.train.ParameterConfig(\n",
    "        cols=[\"k\", \"angle\"],\n",
    "        scales={\"k\": 1e-2, \"angle\": 1.0},\n",
    "        limits={\"k\": [0.0, None], \"angle\": [0.0, math.pi]}\n",
    "    ),\n",
    "    \"ProperTorsions\": descent.train.ParameterConfig(\n",
    "        # fit ks\n",
    "        cols=[\"k\"],\n",
    "        scales={\"k\": 1.0},\n",
    "    ),\n",
    "    \"LeeKrimm\": descent.train.ParameterConfig(\n",
    "        cols=[\"V2\", \"V4\", \"t\", \"s\"],\n",
    "        scales={\"V2\": 1.0, \"V4\": 1.0},\n",
    "        limits={\"V2\": [0.0, None], \"V4\": [0.0, None], \"t\": [0.0, None], \"s\": [0.0, None]}\n",
    "    )\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38024384-4aff-46f9-9555-37cf60a19cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainable = descent.train.Trainable(\n",
    "    force_field=smee_force_field,\n",
    "    parameters=parameters,\n",
    "    attributes={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc04a1d2-8ea0-43c0-bb7a-1fdeb126ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Constraints', 'Bonds', 'Angles', 'ProperTorsions', 'vdW', 'Electrostatics', 'LibraryCharges', 'ToolkitAM1BCC', 'LeeKrimm']\n"
     ]
    }
   ],
   "source": [
    "print(leekrimm_force_field.registered_parameter_handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2f3f33d-41dd-4c92-b13b-aade5798b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional below if you want cool tensorboard logging\n",
    "def write_metrics(\n",
    "        epoch: int,\n",
    "        loss: torch.Tensor,\n",
    "        loss_energy: torch.Tensor,\n",
    "        loss_forces: torch.Tensor,\n",
    "        writer: tensorboardX.SummaryWriter\n",
    "):\n",
    "    print(f\"epoch={epoch} loss={loss.detach().item():.6f}\", flush=True)\n",
    "\n",
    "    writer.add_scalar(\"loss\", loss.detach().item(), epoch)\n",
    "    writer.add_scalar(\"loss_energy\", loss_energy.detach().item(), epoch)\n",
    "    writer.add_scalar(\"loss_forces\", loss_forces.detach().item(), epoch)\n",
    "\n",
    "    writer.add_scalar(\"rmse_energy\", math.sqrt(loss_energy.detach().item()), epoch)\n",
    "    writer.add_scalar(\"rmse_forces\", math.sqrt(loss_forces.detach().item()), epoch)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed660188-8fa5-4981-9480-ab275ad7f3ea",
   "metadata": {},
   "source": [
    "Specify some hyperparameters, n_epochs is intentionally very low to guarantee fast execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b8ba820-b2b4-496c-9dfd-3dea69f30a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4626106-ce81-4b29-90c2-21b7720c9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory to save files in\n",
    "directory = pathlib.Path(\"my-smee-fit\")\n",
    "directory.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766fcdb-5ea1-4cde-92ff-45972bea9142",
   "metadata": {},
   "source": [
    "Run fit below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "535d7e41-913d-4f32-8279-7328d2fba0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard extension so we can view in notebook\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdaa2af1-a22e-46f3-beed-0a208eb9b4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 loss=1849424.250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 loss=1670482.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2 loss=1510521.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3 loss=1367706.375000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4 loss=1240320.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5 loss=1126778.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6 loss=1025618.625000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7 loss=935493.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8 loss=855176.125000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating energies: 100%|███████████████████████| 1/1 [00:02<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9 loss=783553.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainable_parameters = trainable.to_values()\n",
    "device = trainable_parameters.device.type\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "with tensorboardX.SummaryWriter(str(directory)) as writer:\n",
    "    optimizer = torch.optim.Adam([trainable_parameters], lr=LEARNING_RATE, amsgrad=True)\n",
    "    dataset_indices = list(range(len(dataset)))\n",
    "\n",
    "    for i in range(N_EPOCHS):\n",
    "        ff = trainable.to_force_field(trainable_parameters)\n",
    "        total_loss = torch.zeros(size=(1,), device=device)\n",
    "        energy_loss = torch.zeros(size=(1,), device=device)\n",
    "        force_loss = torch.zeros(size=(1,), device=device)\n",
    "        grad = None\n",
    "    \n",
    "        for batch_ids in tqdm.tqdm(\n",
    "            more_itertools.batched(dataset_indices, BATCH_SIZE),\n",
    "            desc='Calculating energies',\n",
    "            ncols=80, total=math.ceil(len(dataset) / BATCH_SIZE)\n",
    "        ):\n",
    "            batch = dataset.select(indices=batch_ids)\n",
    "            true_batch_size = len(dataset)\n",
    "            batch_configs = sum([len(d[\"energy\"]) for d in batch])\n",
    "\n",
    "            e_ref, e_pred, f_ref, f_pred = descent.targets.energy.predict(\n",
    "                batch, ff, topologies, \"mean\"\n",
    "            )   \n",
    "            # L2 loss\n",
    "            batch_loss_energy = ((e_pred - e_ref) ** 2).sum() / true_batch_size\n",
    "            batch_loss_force = ((f_pred - f_ref) ** 2).sum() / true_batch_size\n",
    "\n",
    "            # Equal sum of L2 loss on energies and forces\n",
    "            batch_loss = batch_loss_energy + batch_loss_force\n",
    "\n",
    "            (batch_grad, ) = torch.autograd.grad(batch_loss, trainable_parameters, create_graph=True)\n",
    "            batch_grad = batch_grad.detach()\n",
    "            if grad is None:\n",
    "                grad = batch_grad\n",
    "            else:\n",
    "                grad += batch_grad\n",
    "            \n",
    "            # keep sum of squares to report MSE at the end\n",
    "            total_loss += batch_loss.detach()\n",
    "            energy_loss += batch_loss_energy.detach()\n",
    "            force_loss += batch_loss_force.detach()\n",
    "        \n",
    "        trainable_parameters.grad = grad\n",
    "        \n",
    "        write_metrics(\n",
    "            epoch=i, loss=total_loss, loss_energy=energy_loss,\n",
    "            loss_forces=force_loss, writer=writer\n",
    "        )\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            torch.save(\n",
    "                trainable.to_force_field(trainable_parameters),\n",
    "                directory / f\"force-field-epoch-{i}.pt\"\n",
    "            )\n",
    "\n",
    "    torch.save(\n",
    "        trainable.to_force_field(trainable_parameters),\n",
    "        directory / \"final-force-field.pt\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d141511-d2a4-4e28-84b1-ccd13339147c",
   "metadata": {},
   "source": [
    "Metrics can be viewed in tensorboard below.\n",
    "\n",
    "`tensorboard --logdir my-smee-fit` can also be run on command line instead of in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ba7e487-a3df-4698-8f76-ff01092a5385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f31d005a59b2aeae\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f31d005a59b2aeae\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir my-smee-fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32549d-3952-48a3-ad6f-9979659e2e97",
   "metadata": {},
   "source": [
    "## Convert back to OFFXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73fd1e41-6844-4488-bbd3-b1bd5c648aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for potential in smee_force_field.potentials:\n",
    "    handler_name = potential.parameter_keys[0].associated_handler\n",
    "\n",
    "    parameter_attrs = potential.parameter_cols\n",
    "    parameter_units = potential.parameter_units\n",
    "\n",
    "    if handler_name in [\"Bonds\", \"Angles\"]:\n",
    "        handler = leekrimm_force_field.get_parameter_handler(handler_name)\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "            for j, (p, unit) in enumerate(zip(parameter_attrs, parameter_units)):\n",
    "                setattr(ff_parameter, p, opt_parameters[j] * unit)\n",
    "\n",
    "    elif handler_name in [\"ProperTorsions\"]:\n",
    "        handler = leekrimm_force_field.get_parameter_handler(handler_name)\n",
    "        k_index = parameter_attrs.index('k')\n",
    "        p_index = parameter_attrs.index('periodicity')\n",
    "        # we need to collect the k values into a list across the entries\n",
    "        collection_data = defaultdict(dict)\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "            # find k and the periodicity\n",
    "            k = opt_parameters[k_index] * parameter_units[k_index]\n",
    "            p = int(opt_parameters[p_index])\n",
    "            collection_data[smirks][p] = k\n",
    "        # now update the force field\n",
    "        for smirks, k_s in collection_data.items():\n",
    "            ff_parameter = handler[smirks]\n",
    "            k_mapped_to_p = [k_s[p] for p in ff_parameter.periodicity]\n",
    "            ff_parameter.k = k_mapped_to_p\n",
    "\n",
    "    elif handler_name in [\"ImproperTorsions\"]:\n",
    "        k_index = parameter_attrs.index('k')\n",
    "        handler = leekrimm_force_field.get_parameter_handler(handler_name)\n",
    "        # we only fit the v2 terms for improper torsions so convert to list and set\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "            ff_parameter.k = [opt_parameters[k_index] * parameter_units[k_index]]\n",
    "\n",
    "    elif handler_name == \"LeeKrimm\":\n",
    "        handler = leekrimm_force_field.get_parameter_handler(handler_name)\n",
    "        param_indices = {\n",
    "            name: i for i, name in enumerate(parameter_attrs)\n",
    "        }\n",
    "\n",
    "        for i, opt_parameters in enumerate(potential.parameters):\n",
    "            smirks = potential.parameter_keys[i].id\n",
    "            ff_parameter = handler[smirks]\n",
    "            opt_parameters = opt_parameters.detach().cpu().numpy()\n",
    "\n",
    "            for param_name, unit in zip(parameter_attrs, parameter_units):\n",
    "                value = opt_parameters[param_indices[param_name]] * unit\n",
    "                setattr(ff_parameter, param_name, value)\n",
    "\n",
    "\n",
    "leekrimm_force_field.to_file(\"lee_krimm_final-force-field.offxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fb56d-0894-4a4e-bac4-26c9f5c12ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
